{
  "hash": "745c4e76a0966e96ce60d1a1e6a8314f",
  "result": {
    "markdown": "---\ntitle: \"Bootstrapping and Permutation Testing: A Shiny App\"\nauthor: \"Matthew J. Kmiecik & Ekarin E. Pongpipat\"\ndate: \"7 June 2018\"\ndescription: \"Using Shiny to help understand the difference between bootstrapping and permutation testing.\"\ncategories:\n  - Academic\n  - Shiny\n  - R\n---\n\n\n\n\n<br>\n\n:::{.callout-tip}\nWe have since upgraded this shiny app to a shiny dashboard. [Click here](https://mattkmiecik.shinyapps.io/boot-perm-dash/) to see it!\n:::\n\n# Purpose \n\nThis post serves as a brief overview of the difference between bootstrapping and permutation testing with a shiny app to visualize their differences. The example statistic we use here is a correlation; however, these techniques can be extended to a variety of statistics (e.g., t-test, ANOVA, PCA).\n\n# Shiny App\n\nHere's the shiny app used to illustrate these concepts. [Click here to see the app in full screen.](https://mattkmiecik.shinyapps.io/boot-perm-app/)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nknitr::include_app(\n  \"https://mattkmiecik.shinyapps.io/boot-perm-app/\", height = \"1400px\"\n  )\n```\n\n<iframe src=\"https://mattkmiecik.shinyapps.io/boot-perm-app/?showcase=0\" width=\"672\" height=\"1400px\" data-external=\"1\"></iframe>\n:::\n\n\n## Bootstrapping\n\nWhen you think of boostrapping, think confidence intervals. Bootstrapping **samples observations with replacement** without breaking the relationship between measures (e.g., X and Y). The number of samples is equal to the number of observations (i.e., sample size). After sampling with replacement is finished, the statistic of interest, such as a correlation, is computed and stored.\n\n:::{.callout-tip}\nWhen you think of boostrapping, think confidence intervals.\n:::\n\nThis process explained above is then repeated hundreds or thousands of iterations resulting in a distribution of values for your statistic of interest. This distibution will be centered about the original statistical value that you computed before any resampling occured. In other words, the mean of these stored values will equal your observed statistic.\n\nAs with any distribution, you can calculate what are the lower bounds and upper bounds of values for a given percentage. This percentage is determined by the researcher/statistician/hockey analyst enthusiast and is called a confidence interval (95% is a common confidence interval). These bounds are usually reported in square brackets in the format: confidence interval % [lowerbound, upper bound]. For example, \"There was a positive correlation observed between X and Y, _r_ = .31, 95% CI [.21, .41].\"\n\n## Permutation Testing\n\nWhen you think of permutation testing, think of p-values. Permutation testing **does not sample observations with replacement, but instead breaks the relationship between measures (e.g., X and Y).** This is done by shuffling/randomizing/sampling the observed data points for one variable, while keeping the other (or others) intact. In terms of correlation, this would mean that X would be shuffled within the sample, while Y remained the original values. After the responses for one variable are randomized the statistic of interest, such as a correlation, is computed and stored.\n\n:::{.callout-tip}\nWhen you think of boostrapping, think confidence intervals.\n:::\n\nThis process explained above is then repeated hundreds or thousands of iterations resulting in a distribution of values for your statistic of interest. This distibution **will not be centered about the original statistic value that you computed before any shuffling occured, but rather will be centered around the null.** In terms of correlation, a null distribution would center about _r_ = 0; meaning no linear relationship between variables.\n\nIn other words, a null distribution is created by shuffling the values in X but not Y. This is because the relationship has been broken between X and Y. \n\nA p-value is calculated by first counting the number of statistical values that are more extreme than your observed statistic. Put another way, how many times did the statistical value that emerged from a \"null distribution\" surpass your original computed statistic (before any shuffling). Then, you take the number of times that the null distribution is more extreme than your original value and divide it by the number of permutation iterations (number of observations in your null distribution). \n\nFor example, let's say I ran a permutation test on a correlation of _r_ = .5 and shuffled X, kept Y, computed their correlation, stored this value, and repeated this 100 times. Out of 100 times, there were 4 correlations that emerged that were greater than .5. Therefore, my p-value for this correlation would be 4/100 = 0.04.\n\n# Shiny App Code\n\nBelow is the code that runs the shiny app:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Packages required ----\nlibrary(shiny) \nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(purrr)\nlibrary(broom)\nlibrary(MASS)\nlibrary(modelr)\nlibrary(shinythemes)\nlibrary(shinycssloaders)\n\n# Global aesthetics ----\n\n# Main color palette (Flatly bootstrap theme)\nflatlyPal <- c('#2C3E50', '#18BC9C', '#94A5A6', '#3498DC', '#F39C13', '#E74C3C') \n\n# loading spinner options\noptions(spinner.color = flatlyPal[1], spinner.type = 8)\n\n# Plot constant\nplotFinish <- theme(plot.title = element_text(hjust = 0.5, size = 15),\n                    text = element_text(size = 15),\n                    plot.caption = element_text(hjust = .5)\n                    )\n\n# Turning off scientific notation for p-values\noptions(scipen = 999)\n\n# UI ----\n\n# Define UI for application that draws a histogram\nui <- fluidPage(theme = shinytheme(\"flatly\"),\n  \n  # Title\n  h2(\"Bootstrapping and Permutation Testing\"),\n  \n  # Author info\n  h4(\"Matthew J. Kmiecik & Ekarin E. Pongpipat\"),\n  \n  # Blogpost info\n  p(\"See our \", \n    a(\"blog post\", href=\"https://mattkmiecik.com/post-Bootstrapping-and-Permutation-Testing-Shiny-App.html\"), \n    \"for more information about this shiny app.\"\n    ),\n  \n  # Sidebar with a slider input for number of bins \n  sidebarLayout(\n    sidebarPanel(\n      sliderInput(inputId = \"rUser\",\n                  label = \"Correlation (r): \",\n                  min = -1,\n                  max = 1,\n                  value = .3,\n                  step = .1,\n                  ticks = FALSE),\n      sliderInput(inputId = \"sampleN\",\n                  label = \"Sample size (N): \",\n                  min = 10,\n                  max = 200,\n                  value = 50,\n                  step = 10,\n                  ticks = FALSE),\n      sliderInput(inputId = \"bootIters\",\n                  label = \"Bootstrap Iterations: \",\n                  min = 100,\n                  max = 2000,\n                  value = 100,\n                  step = 100,\n                  ticks = FALSE),\n      sliderInput(inputId = \"ciUser\",\n                  label = \"Bootstrap Confidence Interval: \",\n                  min = .80,\n                  max = .99,\n                  value = .90,\n                  step = .01,\n                  ticks = FALSE),\n      sliderInput(inputId = \"permIters\",\n                  label = \"Permutation Iterations: \",\n                  min = 100,\n                  max = 2000,\n                  value = 100,\n                  step = 100,\n                  ticks = FALSE), \n      width = \"2\"),\n    \n    # Plots\n    mainPanel(\n      flowLayout(\n        plotOutput(\"scatterPlot\") %>% withSpinner(),\n        plotOutput(\"bootPlot\")  %>% withSpinner(),\n        plotOutput(\"permPlot\")  %>% withSpinner()\n      )\n    )\n  )\n)\n\n# Server ----\nserver <- function(input, output) {\n\n  # Defined variables\n  vars    <- 2 # Minimum of 2 variables are required for correlation\n  mu <- rep(0, vars) # Means of all the vars are 0\n  \n  # Calculates sigma\n  re_sigma <- reactive({matrix(input$rUser, nrow = vars, ncol = vars)})\n  \n  # Establihses sigma = 1\n  re_sigma2 <- reactive({re_sigma() - diag(vars)*(input$rUser) + diag(vars)}) \n  \n  # Gathers correlations\n  re_rawvars <- reactive({as.tibble(mvrnorm(n = input$sampleN, \n                                            mu = mu, \n                                            Sigma = re_sigma2(), \n                                            empirical = T\n                                            )\n                                    ) %>%\n      rename(x = V1, y = V2)}\n      )\n  \n  # Bootstrapping procedure ----\n  re_bootResults <- reactive({re_rawvars() %>%\n    broom::bootstrap(input$bootIters) %>%\n    do(tidy(lm(scale(y) ~ scale(x), .))) %>%\n    filter(term != '(Intercept)')})\n   \n  # Confidence interval calculations ----\n  re_ciUserL <- reactive({(1-input$ciUser)/2})\n  re_ciUserU <- reactive({input$ciUser + re_ciUserL()})\n  re_ciObs <- reactive({quantile(re_bootResults()$estimate, \n                                 c(re_ciUserL(), re_ciUserU()))})\n\n  # Permutation testing procedure ----\n  # From: https://www.rdocumentation.org/packages/modelr/versions/0.1.1/topics/permute\n  re_perms <- reactive({re_rawvars() %>% permute(input$permIters, y)})\n  re_models <- reactive({map(re_perms()[[\"perm\"]], \n                             ~ lm(scale(y) ~ scale(x), data = .))})\n  re_tidyd <- reactive({map_df(re_models(), broom::tidy, .id = 'id') %>% \n      filter(term != '(Intercept)')})\n  \n  # Calculates p value from permutation testing\n  re_permPVal <- reactive({\n    if (input$rUser >= 0) {\n      (sum(re_tidyd()[[\"estimate\"]] >= input$rUser) + 1)/input$permIters\n    } else if ( input$rUser < 0 ) {\n      (sum(re_tidyd()[[\"estimate\"]] <= input$rUser) + 1)/input$permIters\n    }\n  }\n  )\n    \n  # Scatterplot ----\n  \n   output$scatterPlot <- renderPlot({\n     \n     # Caption for Scatterplot\n     corResP <- round(cor.test(re_rawvars()$x, re_rawvars()$y)$p.value, 3)\n     corResPFinal <- ifelse(corResP > .001, corResP, .001)\n     pSign <- ifelse(corResP > .001, '= ', '< ')\n     scatRes <- paste0('r (', input$sampleN-2, ') = ', input$rUser,\n                       ', p ', pSign,corResPFinal)\n     \n     # Plot\n     ggplot(re_rawvars(), aes(x, y)) +\n       geom_smooth(method = 'lm', se = T, \n                   color = flatlyPal[6], fill = flatlyPal[3]) +\n       geom_point(color = flatlyPal[1], alpha = 2/3) +\n       labs(x = 'X', y = 'Y', \n            title = 'Scatterplot', caption = scatRes) +\n       theme_classic() +\n       plotFinish\n     \n        })\n\n  # Bootstrap Plot ----\n   output$bootPlot <- renderPlot({\n     ggplot(re_bootResults(), aes(estimate)) +\n       geom_histogram(binwidth = .05, fill = flatlyPal[1]) +\n       geom_errorbarh(aes(xmin = re_ciObs()[[1]], xmax = re_ciObs()[[2]], \n                          x = input$rUser, y = nrow(re_bootResults())/10), \n                      height = 0, color = flatlyPal[2], size = 1) +\n       geom_point(aes(x = input$rUser, y = nrow(re_bootResults())/10),\n                  size = 4, color = flatlyPal[2]) +\n       labs(x = 'Correlation', y = 'Frequency', \n            title = 'Bootstrapping', \n            caption = paste0(input$ciUser*100, '% CI [', \n                             round(re_ciObs()[[1]], 2), ', ',\n                             round(re_ciObs()[[2]], 2), ']')\n            ) +\n       theme_classic() +\n       plotFinish\n   })\n   \n   # Permutation plot ----\n   output$permPlot <- renderPlot({\n     ggplot(re_tidyd(), aes(estimate)) +\n       geom_histogram(binwidth = .05, fill = flatlyPal[1]) +\n       geom_vline(aes(xintercept = input$rUser), \n                  color = flatlyPal[6], linetype = 2, size = .75) +\n       labs(x = 'Correlation', y = 'Frequency', \n            title = 'Permutation Testing',\n            caption = paste0('r = ', input$rUser, ', p = ', round(re_permPVal(), 5))\n            ) +\n       theme_classic() +\n       plotFinish\n     \n   })\n}\n\n# Application ----\nshinyApp(ui = ui, server = server)\n```\n:::\n\n\n# References\n\nReaders who would like more theoretical or technical explanations of boostrapping and permutation testing are encouraged to read:\n\n+ Efron, B. (1979). Bootstrap methods: Another look at the jacknife. _The Annals of Statistics, 7_(1), 1-26. \n\n+ Ludbrook, J., & Dudley, H. (1998). Why Permutation Tests are Superior to t and F Tests in Biomedical Research. _The American Statistician, 52_(2), 127-132. doi:10.1080/00031305.1998.10480551\n\n+ Wright, D. B., London, K., & Field, A. P. (2018). Using Bootstrap Estimation and the Plug-in Principle for Clinical Psychology Data. _Journal of Experimental Psychopathology, 2_(2). doi:10.5127/jep.013611\n\n<!-- disqus START -->\n\n<div id=\"disqus_thread\"></div>\n<script>\n/**\n*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.\n*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/\n/*\nvar disqus_config = function () {\nthis.page.url = 'https://mattkmiecik.com/post-Bootstrapping-and-Permutation-Testing-Shiny-App';  // Replace PAGE_URL with your page's canonical URL variable\nthis.page.identifier = 'post-Bootstrapping-and-Permutation-Testing-Shiny-App'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable\n};\n*/\n(function() { // DON'T EDIT BELOW THIS LINE\nvar d = document, s = d.createElement('script');\ns.src = 'https://mattkmiecik.disqus.com/embed.js';\ns.setAttribute('data-timestamp', +new Date());\n(d.head || d.body).appendChild(s);\n})();\n</script>\n<noscript>Please enable JavaScript to view the <a href=\"https://disqus.com/?ref_noscript\">comments powered by Disqus.</a></noscript>\n\n<!-- disqus END -->\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}