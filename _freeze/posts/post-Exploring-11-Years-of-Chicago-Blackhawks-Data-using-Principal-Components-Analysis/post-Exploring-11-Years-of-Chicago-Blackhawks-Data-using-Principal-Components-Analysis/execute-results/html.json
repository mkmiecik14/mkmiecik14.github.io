{
  "hash": "48c51557557f8c0f9db35aa5fe7b3d10",
  "result": {
    "markdown": "---\ntitle: \"Exploring 11 Years of Chicago Blackhawk's Data using Principal Components Analysis\"\nauthor: \"Matthew J. Kmiecik & Ekarin E. Pongpipat\"\ndate: \"7 March 2019\"\ndescription: \"Two grad students get over zealous with PCA and NHL data.\"\nimage: \"./thumbnail.png\"\ncategories:\n  - Academic\n  - Hockey Analytics\n  - R\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n    toc-location: left\n    smooth-scroll: true\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\n---\n\n\n\n\n<br >\n\nIn this post we explore 11 seasons (2007 - 2018) of team summary data from the Chicago Blackhawks of the National Hockey League (NHL). Our question was, \"Are there any summary measures, such as goals scored or save percentage, that predict playoff performance or championship wins?\"\n\n<br >\n\nWe explore these data using a variety of techniques, such as:\n\n<br >\n\n**Z-scores across time**\n\n+ Finding #1a: 2007-2008 was characterized by low time on ice (TOI), Corsi for (CF), and elevated served penalty minutes\n\n+ Finding #1b: 2012-2013 was characterized by elevated save and shooting percentage \n\n<br >\n\n**Correlations**\n\n+ Finding #2a: Powerplay units are more selective in their shooting resulting in decreased Corsi estimates; however, this is a speculative hypothesis and needs additional study\n\n+ Finding #2b: Through time, Blackhawks had more time on ice (likely more overtime play) and decreased their penalties served and taken. Perhaps decreased penalties are related to changes in rules and league-wide game play style\n\n<br >\n\n**Principal Components Analysis (PCA)**\n\n+ Finding #3a: Component 1 was characterized by the Blackhawks improving as a team over time in penalty minutes and taking more shots, while simultaneously receiving more shots and goals against\n\n+ Finding #3b: Component 2 was dominated by the 2012-2013 season that was characterized by excellent defense and great offense. This season was the Blackhawk's Presidents' Trophy winning season, a Stanley Cup winning season, a shortened lockout season, as well as setting franchise records for win streaks\n\n<br >\n\n# Setup\n\nHere are the packages that we'll use for these analyses and functions to style the output/plots.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Packages ----\nlibrary(tidyverse)    # For data manipulation, plotting, etc. \nlibrary(httr)         # To import data on github\nlibrary(TExPosition)  # PCA tools\nlibrary(ggrepel)      # Plotting tool for ggplot2\nlibrary(kableExtra)   # HTML table tools\nlibrary(RColorBrewer) # Nice plotting colors\nlibrary(gridExtra)    # Plotting tools\n\n# Custom functions ----\n# nice_table() simplifies the printing of HTML tables using kable\nnice_table <- function(x){\n  \n  kable(x) %>%\n    kable_styling(bootstrap_options = c('striped', 'hover', 'responsive', 'condensed'))\n  \n}\n\n# Color palettes ----\nrdgy <- brewer.pal(n = 11, name = \"RdGy\") # display.brewer.pal(11, \"RdGy\")\n\n# ggplot2 finishings\npca_furnish <- theme_classic() +\n  theme(axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        axis.line = element_blank()\n        )\n```\n:::\n\n\n<br >\n\n## Data Import\n\nLet's first prepare the data for analysis. These data were downloaded from [Corsica's](http://corsica.hockey/) team stats tool. We've prepared these data for you and are available for import into R like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Link to raw data on Github\nlink <- \"https://raw.githubusercontent.com/mkmiecik14/mkmiecik14.github.io/master/data/nhl-team-data-corsica.csv\"\n\n# from https://stackoverflow.com/questions/60714074/download-csv-file-from-github-using-httr-get-request\ndata <- GET(link)\nnhl_data <- read_csv(content(data, \"raw\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 331 Columns: 28\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Team, Season\ndbl (26): GP, TOI, CF, CA, C+/-, CF%, CF/60, CA/60, GF, GA, G+/-, GF%, GF/60...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\n<br >\n\n## Data Preparation\n\nTo make things simple, without losing information, we'll use Chicago Blackhawk's data from the 2007-2008 season up through the 2017-2018 season (11 years of data) and only a subset of the available metrics. These metrics include:\n\n+ Games Played (GP)\n+ Time on Ice (TOI)\n+ Corsi For (CF) = Shot attempts for at even strength: Shots + Blocks + Misses\n+ Corsi Against (CA) = Shot attempts against at even strength: Shots + Blocks + Misses\n+ Goals For (GF)\n+ Goals Against (GA)\n+ Penalty minutes served (PENT)\n+ Penalty minutes drawn (PEND)\n+ Shooting Percentage (ShootPerc)\n+ Save Percentage (SavePerc)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Preparing Hawks data ----\nhawks_data <-  nhl_data %>%\n  select(Team:CA, GF, GA, PENT, PEND, ShootPerc = `Sh%`, SavePerc = `Sv%`) %>%\n  filter(Team == \"CHI\") %>%\n  separate(Season, into = c(\"Start_Year\", \"Season\")) %>%\n  mutate(Team = NULL, \n         Start_Year = NULL,\n         Season = as.numeric(Season)\n         )\n\n# Prints data\nnice_table(hawks_data)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-responsive table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> Season </th>\n   <th style=\"text-align:right;\"> GP </th>\n   <th style=\"text-align:right;\"> TOI </th>\n   <th style=\"text-align:right;\"> CF </th>\n   <th style=\"text-align:right;\"> CA </th>\n   <th style=\"text-align:right;\"> GF </th>\n   <th style=\"text-align:right;\"> GA </th>\n   <th style=\"text-align:right;\"> PENT </th>\n   <th style=\"text-align:right;\"> PEND </th>\n   <th style=\"text-align:right;\"> ShootPerc </th>\n   <th style=\"text-align:right;\"> SavePerc </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 2008 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 3423.00 </td>\n   <td style=\"text-align:right;\"> 2600 </td>\n   <td style=\"text-align:right;\"> 2629 </td>\n   <td style=\"text-align:right;\"> 143 </td>\n   <td style=\"text-align:right;\"> 130 </td>\n   <td style=\"text-align:right;\"> 368 </td>\n   <td style=\"text-align:right;\"> 365 </td>\n   <td style=\"text-align:right;\"> 9.04 </td>\n   <td style=\"text-align:right;\"> 91.92 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2009 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3646.73 </td>\n   <td style=\"text-align:right;\"> 3286 </td>\n   <td style=\"text-align:right;\"> 2655 </td>\n   <td style=\"text-align:right;\"> 146 </td>\n   <td style=\"text-align:right;\"> 124 </td>\n   <td style=\"text-align:right;\"> 335 </td>\n   <td style=\"text-align:right;\"> 368 </td>\n   <td style=\"text-align:right;\"> 7.45 </td>\n   <td style=\"text-align:right;\"> 92.42 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2010 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3881.33 </td>\n   <td style=\"text-align:right;\"> 3784 </td>\n   <td style=\"text-align:right;\"> 2907 </td>\n   <td style=\"text-align:right;\"> 178 </td>\n   <td style=\"text-align:right;\"> 147 </td>\n   <td style=\"text-align:right;\"> 276 </td>\n   <td style=\"text-align:right;\"> 299 </td>\n   <td style=\"text-align:right;\"> 8.30 </td>\n   <td style=\"text-align:right;\"> 90.53 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2011 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3955.85 </td>\n   <td style=\"text-align:right;\"> 3704 </td>\n   <td style=\"text-align:right;\"> 3314 </td>\n   <td style=\"text-align:right;\"> 167 </td>\n   <td style=\"text-align:right;\"> 144 </td>\n   <td style=\"text-align:right;\"> 239 </td>\n   <td style=\"text-align:right;\"> 277 </td>\n   <td style=\"text-align:right;\"> 8.06 </td>\n   <td style=\"text-align:right;\"> 92.03 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2012 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3944.77 </td>\n   <td style=\"text-align:right;\"> 3698 </td>\n   <td style=\"text-align:right;\"> 3290 </td>\n   <td style=\"text-align:right;\"> 166 </td>\n   <td style=\"text-align:right;\"> 164 </td>\n   <td style=\"text-align:right;\"> 270 </td>\n   <td style=\"text-align:right;\"> 287 </td>\n   <td style=\"text-align:right;\"> 8.15 </td>\n   <td style=\"text-align:right;\"> 90.99 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2013 </td>\n   <td style=\"text-align:right;\"> 48 </td>\n   <td style=\"text-align:right;\"> 2300.80 </td>\n   <td style=\"text-align:right;\"> 2103 </td>\n   <td style=\"text-align:right;\"> 1783 </td>\n   <td style=\"text-align:right;\"> 105 </td>\n   <td style=\"text-align:right;\"> 68 </td>\n   <td style=\"text-align:right;\"> 151 </td>\n   <td style=\"text-align:right;\"> 159 </td>\n   <td style=\"text-align:right;\"> 8.97 </td>\n   <td style=\"text-align:right;\"> 92.94 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2014 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3979.35 </td>\n   <td style=\"text-align:right;\"> 3890 </td>\n   <td style=\"text-align:right;\"> 3129 </td>\n   <td style=\"text-align:right;\"> 182 </td>\n   <td style=\"text-align:right;\"> 149 </td>\n   <td style=\"text-align:right;\"> 244 </td>\n   <td style=\"text-align:right;\"> 231 </td>\n   <td style=\"text-align:right;\"> 8.44 </td>\n   <td style=\"text-align:right;\"> 91.39 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2015 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3980.10 </td>\n   <td style=\"text-align:right;\"> 4003 </td>\n   <td style=\"text-align:right;\"> 3462 </td>\n   <td style=\"text-align:right;\"> 150 </td>\n   <td style=\"text-align:right;\"> 128 </td>\n   <td style=\"text-align:right;\"> 225 </td>\n   <td style=\"text-align:right;\"> 248 </td>\n   <td style=\"text-align:right;\"> 6.87 </td>\n   <td style=\"text-align:right;\"> 93.54 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2016 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3985.37 </td>\n   <td style=\"text-align:right;\"> 3680 </td>\n   <td style=\"text-align:right;\"> 3585 </td>\n   <td style=\"text-align:right;\"> 135 </td>\n   <td style=\"text-align:right;\"> 141 </td>\n   <td style=\"text-align:right;\"> 216 </td>\n   <td style=\"text-align:right;\"> 234 </td>\n   <td style=\"text-align:right;\"> 6.81 </td>\n   <td style=\"text-align:right;\"> 92.81 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2017 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 4053.47 </td>\n   <td style=\"text-align:right;\"> 3759 </td>\n   <td style=\"text-align:right;\"> 3692 </td>\n   <td style=\"text-align:right;\"> 164 </td>\n   <td style=\"text-align:right;\"> 136 </td>\n   <td style=\"text-align:right;\"> 206 </td>\n   <td style=\"text-align:right;\"> 222 </td>\n   <td style=\"text-align:right;\"> 8.17 </td>\n   <td style=\"text-align:right;\"> 93.31 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2018 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 3940.41 </td>\n   <td style=\"text-align:right;\"> 4199 </td>\n   <td style=\"text-align:right;\"> 3821 </td>\n   <td style=\"text-align:right;\"> 156 </td>\n   <td style=\"text-align:right;\"> 173 </td>\n   <td style=\"text-align:right;\"> 214 </td>\n   <td style=\"text-align:right;\"> 261 </td>\n   <td style=\"text-align:right;\"> 7.08 </td>\n   <td style=\"text-align:right;\"> 91.82 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nLet's also prepare a table of notable events of every year in this data set for the Chicago Blackhawks, including their Stanley Cup wins (3) and their playoff success:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initializing Chicago Blackhawks notable events table ----\n# SCW = Stanley Cup Wins\n# PF = Playoff Finish:\n#   0 = Did not make playoffs\n#   1 = Lost in first round\n#   2 = Lost in second round\n#   3 = Lost in conference finals\n#   4 = Lost in Stanley Cup final\n#   5 = Won Stanley Cup\nhawks_events <- tibble(Season = hawks_data$Season,\n                       SCW = factor(c(0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0)),\n                       PF  = factor(c(0, 3, 5, 1, 1, 5, 3, 5, 1, 1, 0))\n                       )\n```\n:::\n\n\n<br >\n\n## Z-Scores\n\nPrior to exploring these data and how they've changed over time, we have to:\n\n1. Adjust all scores by the number of games played due to a shorted 2012-2013 season. We do this by dividing each metric by the number of games played\n2. Compute z-scores of all measures to facilitate comparisons\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Preprocesses, adjusts, and z-scores hawks data ----\nhawks_data_long <- hawks_data %>% \n  gather(Meas, Val, -Season, -GP) %>%\n  group_by(Meas) %>%\n  mutate(Val_Adj = Val/GP,               # adjusts based on games played\n         Val_Zscore = scale(Val_Adj)     # computes z-scores\n         ) %>%\n  ungroup() %>%\n  mutate(sig = factor(ifelse(abs(Val_Zscore) > 1.96, \"p < .05\", \"p > .05\"))) %>% # z score > 1.96\n  inner_join(., hawks_events, by = \"Season\") # adds notable hawks events\n```\n:::\n\n\nPlotting the z-scores of each measure across time allows us to compare across measures using a standardized unit:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plots all measures together ----\nggplot(hawks_data_long, aes(factor(Season), Val_Zscore)) +\n  geom_path(aes(group = 1), color = rdgy[8]) +\n  geom_point(aes(color = sig, shape = SCW), size = 1.75) +\n  scale_color_manual(values = c(rdgy[3], rdgy[10]), name = \"Z-Score\") +\n  scale_shape_discrete(name = \"Stanley Cup Wins\") +\n  scale_y_continuous(breaks = c(-2, 0, 2), minor_breaks = NULL) +\n  coord_cartesian(ylim = c(-3,3)) +\n  theme_minimal() + \n  labs(x = \"\\n Season\", \n       y = \"\\n Measurement (Z-Score)\",\n       title = \"Chicago Blackhawk's Performance 2007-2018\"\n       ) +\n  facet_wrap(~Meas, nrow = 3) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"bottom\"\n        )\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWhen inspecting these plots in relation to the Chicago Blackhawk's 3 Stanley Cup wins (triangles), we see very little that stands out. It seems like the 2012-2013 season was a unique one, such that it was a Stanley Cup winning team and their regular season Save Percentage and Shooting Percentage were much greater than their other years. Perhaps these two metrics are important for winning the Presidents' Trophy (awarded to the NHL team finishing with the highest total points), which the Blackhawk's received at the end of their 2012-2013 season.\n\nAdditionally, the Blackhawk's 2007-2008 season seemed their worst season with the team recording statistically the least amount of time on ice (TOI), the most penalty minutes served (PENT), and the lowest Corsi For (CF) compared to the following decade of play. The 2007-2008 season was a tumultuous time for the Hawks, including a change in ownership and the later hire of Coach Joel Quennevill (see [NYT article](https://www.nytimes.com/2015/06/05/sports/hockey/when-ownership-changed-to-rocky-wirtz-in-2007-so-did-the-blackhawks.html)). It is likely that the change in ownership, hiring of Coach Q, and the acquisition of Jonathon Towes and Patrick Kane that led to the drastic improvement of team stats in the years following.\n\n<br >\n\n## Correlations\n\nNow let's examine how the various team stats/measurements relate to each other by computing their correlations and visualizing them with a heatmap:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Converts back to wide format\nhawks_data_wide <- hawks_data_long %>% \n  select(Season, Meas, Val_Zscore) %>% \n  spread(Meas, Val_Zscore)\n\n# Computes correlations\nhawks_cors <- cor(hawks_data_wide)\n\n# Correlations to long format for plotting\nhawks_cors_long <- hawks_cors %>%\n  reshape2::melt() %>%\n  arrange(Var1, Var2)\n\n# Correlation heatmap\nggplot(hawks_cors_long, aes(x = Var1, y = Var2, fill = value)) +\n  geom_raster() + \n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.title = element_blank()\n        ) +\n  scale_fill_distiller(palette = \"BrBG\", \n                       limits = c(-1, 1), \n                       name = \"Correlation\"\n                       )\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAn interesting section that sticks out in the heatmap is the negative relationships between penalties, both served and drawn, and corsi, both for and against. This suggests that as the Hawks improved at drawing penalties, as well worsened at taking penalties, the amount of shots taken at the net decreased. This also came with a decrease in shots let up by the Hawks. My only explanation for this could be that as teams are on the powerplay, they become more selective with their shots, thus decreasing Corsi For and Corsi Against. This sort of aligns with our [previous post](https://mattkmiecik.com/post-Multilevel-Modeling-in-R-with-NHL-Power-Play-Data.html) that determined a decrease in NHL powerplay goals in the last decade. How is decline relates to Corsi is yet to be determined.\n\n<br >\n\n# Principal Components Analysis (PCA)\n\nWe've explored these measures individually by plotting their change over time (2007-2018) as well as examining their correlations; however, it's difficult to extract meaningful relationships between these variables, especially when there are a lot of variables to consider. Also, all relationships between the variables are not considered simultaneously, but rather one at a time (e.g., bivariate correlations). Is there some way to analyze these variables' relationships simultaneously, while also reducing their complexity?\n\nOne method of doing this is principal components analysis (PCA). PCA is often called a data reduction technique because it reduces the data structure into manageable \"components\" that explain proportions of variability in the data. In order to understand what each component means, we examine how information (e.g., years or measurements) is spread across the components.\n\nAdditionally, the PCA that we will demonstrate below places a constraint on the components such that they are orthogonal to each other, meaning that each component is perfectly uncorrelated with every other component (_r_ = 0).\n\nWe go over the very basics of PCA below. There is much more to this technique than we present, so we recommend the interested reader the following papers on this statistical technique:\n\n+ Abdi, H., & Williams, L.J. (2010). <a href=\"https://www.utdallas.edu/~herve/abdi-awPCA2010.pdf\" target=\"_blank\">Principal component analysis</a>. _Wiley Interdisciplinary Reviews: Computational Statistics_, 2, 433-459.\n\n+ Abdi, H. (2007). <a href=\"https://www.utdallas.edu/~herve/Abdi-SVD2007-pretty.pdf\" target=\"_blank\">Singular Value Decomposition (SVD) and Generalized Singular Value Decomposition (GSVD)</a>. In N.J. Salkind (Ed.): _Encyclopedia of Measurement and Statistics_. Thousand Oaks (CA): Sage. pp. 907-912.\n\n<br >\n\nWe first need to preprocess our data such that each column (i.e., measurement) has a mean of 0 and a standard deviation of 1. In other words, each column should be in z-score format. We've already done this above when exploring these data.\n\nA unique feature of this dataset is the shortened 2012-2013 NHL season that we accounted for by scaling each column by the number of games played that season. We already did this above and do not need to repeat this step.\n\nTherefore, the first step here is to convert these data into a matrix format with the season years on the rows as row names:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Converts to matrix\nhawks_data_mat <- hawks_data_wide %>% select(-Season) %>% as.matrix()\nrownames(hawks_data_mat) <- hawks_data_wide$Season # Adds rownames\n\nround(hawks_data_mat, 4) %>% nice_table() # Prints HTML table\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-responsive table-condensed\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> CA </th>\n   <th style=\"text-align:right;\"> CF </th>\n   <th style=\"text-align:right;\"> GA </th>\n   <th style=\"text-align:right;\"> GF </th>\n   <th style=\"text-align:right;\"> PEND </th>\n   <th style=\"text-align:right;\"> PENT </th>\n   <th style=\"text-align:right;\"> SavePerc </th>\n   <th style=\"text-align:right;\"> ShootPerc </th>\n   <th style=\"text-align:right;\"> TOI </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2008 </td>\n   <td style=\"text-align:right;\"> -1.3890 </td>\n   <td style=\"text-align:right;\"> -2.4688 </td>\n   <td style=\"text-align:right;\"> -0.4854 </td>\n   <td style=\"text-align:right;\"> -0.9264 </td>\n   <td style=\"text-align:right;\"> 1.8463 </td>\n   <td style=\"text-align:right;\"> 2.1908 </td>\n   <td style=\"text-align:right;\"> -0.2058 </td>\n   <td style=\"text-align:right;\"> 0.3069 </td>\n   <td style=\"text-align:right;\"> -2.3384 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2009 </td>\n   <td style=\"text-align:right;\"> -1.4910 </td>\n   <td style=\"text-align:right;\"> -0.9281 </td>\n   <td style=\"text-align:right;\"> -1.0362 </td>\n   <td style=\"text-align:right;\"> -0.9636 </td>\n   <td style=\"text-align:right;\"> 1.7270 </td>\n   <td style=\"text-align:right;\"> 1.4019 </td>\n   <td style=\"text-align:right;\"> -0.2954 </td>\n   <td style=\"text-align:right;\"> -0.4589 </td>\n   <td style=\"text-align:right;\"> -1.4947 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2010 </td>\n   <td style=\"text-align:right;\"> -0.8442 </td>\n   <td style=\"text-align:right;\"> 0.3075 </td>\n   <td style=\"text-align:right;\"> 0.3334 </td>\n   <td style=\"text-align:right;\"> 1.1052 </td>\n   <td style=\"text-align:right;\"> 0.3829 </td>\n   <td style=\"text-align:right;\"> 0.2989 </td>\n   <td style=\"text-align:right;\"> -0.3895 </td>\n   <td style=\"text-align:right;\"> -0.1004 </td>\n   <td style=\"text-align:right;\"> -0.0621 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2011 </td>\n   <td style=\"text-align:right;\"> 0.2002 </td>\n   <td style=\"text-align:right;\"> 0.1090 </td>\n   <td style=\"text-align:right;\"> 0.1547 </td>\n   <td style=\"text-align:right;\"> 0.3941 </td>\n   <td style=\"text-align:right;\"> -0.0456 </td>\n   <td style=\"text-align:right;\"> -0.3929 </td>\n   <td style=\"text-align:right;\"> -0.3148 </td>\n   <td style=\"text-align:right;\"> -0.2016 </td>\n   <td style=\"text-align:right;\"> 0.3930 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2012 </td>\n   <td style=\"text-align:right;\"> 0.1387 </td>\n   <td style=\"text-align:right;\"> 0.0941 </td>\n   <td style=\"text-align:right;\"> 1.3457 </td>\n   <td style=\"text-align:right;\"> 0.3294 </td>\n   <td style=\"text-align:right;\"> 0.1492 </td>\n   <td style=\"text-align:right;\"> 0.1867 </td>\n   <td style=\"text-align:right;\"> -0.3666 </td>\n   <td style=\"text-align:right;\"> -0.1637 </td>\n   <td style=\"text-align:right;\"> 0.3253 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2013 </td>\n   <td style=\"text-align:right;\"> -0.4876 </td>\n   <td style=\"text-align:right;\"> -0.1673 </td>\n   <td style=\"text-align:right;\"> -1.5027 </td>\n   <td style=\"text-align:right;\"> 1.1941 </td>\n   <td style=\"text-align:right;\"> -0.1503 </td>\n   <td style=\"text-align:right;\"> -0.0384 </td>\n   <td style=\"text-align:right;\"> 3.0104 </td>\n   <td style=\"text-align:right;\"> 2.8614 </td>\n   <td style=\"text-align:right;\"> 0.2384 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2014 </td>\n   <td style=\"text-align:right;\"> -0.2745 </td>\n   <td style=\"text-align:right;\"> 0.5705 </td>\n   <td style=\"text-align:right;\"> 0.4525 </td>\n   <td style=\"text-align:right;\"> 1.3638 </td>\n   <td style=\"text-align:right;\"> -0.9417 </td>\n   <td style=\"text-align:right;\"> -0.2994 </td>\n   <td style=\"text-align:right;\"> -0.3467 </td>\n   <td style=\"text-align:right;\"> -0.0414 </td>\n   <td style=\"text-align:right;\"> 0.5365 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2015 </td>\n   <td style=\"text-align:right;\"> 0.5801 </td>\n   <td style=\"text-align:right;\"> 0.8509 </td>\n   <td style=\"text-align:right;\"> -0.7981 </td>\n   <td style=\"text-align:right;\"> -0.7050 </td>\n   <td style=\"text-align:right;\"> -0.6105 </td>\n   <td style=\"text-align:right;\"> -0.6546 </td>\n   <td style=\"text-align:right;\"> -0.2396 </td>\n   <td style=\"text-align:right;\"> -0.7035 </td>\n   <td style=\"text-align:right;\"> 0.5411 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2016 </td>\n   <td style=\"text-align:right;\"> 0.8957 </td>\n   <td style=\"text-align:right;\"> 0.0495 </td>\n   <td style=\"text-align:right;\"> -0.0239 </td>\n   <td style=\"text-align:right;\"> -1.6747 </td>\n   <td style=\"text-align:right;\"> -0.8832 </td>\n   <td style=\"text-align:right;\"> -0.8229 </td>\n   <td style=\"text-align:right;\"> -0.2759 </td>\n   <td style=\"text-align:right;\"> -0.7288 </td>\n   <td style=\"text-align:right;\"> 0.5732 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2017 </td>\n   <td style=\"text-align:right;\"> 1.1703 </td>\n   <td style=\"text-align:right;\"> 0.2455 </td>\n   <td style=\"text-align:right;\"> -0.3217 </td>\n   <td style=\"text-align:right;\"> 0.2001 </td>\n   <td style=\"text-align:right;\"> -1.1170 </td>\n   <td style=\"text-align:right;\"> -1.0098 </td>\n   <td style=\"text-align:right;\"> -0.2510 </td>\n   <td style=\"text-align:right;\"> -0.1553 </td>\n   <td style=\"text-align:right;\"> 0.9891 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2018 </td>\n   <td style=\"text-align:right;\"> 1.5014 </td>\n   <td style=\"text-align:right;\"> 1.3372 </td>\n   <td style=\"text-align:right;\"> 1.8817 </td>\n   <td style=\"text-align:right;\"> -0.3171 </td>\n   <td style=\"text-align:right;\"> -0.3573 </td>\n   <td style=\"text-align:right;\"> -0.8603 </td>\n   <td style=\"text-align:right;\"> -0.3252 </td>\n   <td style=\"text-align:right;\"> -0.6149 </td>\n   <td style=\"text-align:right;\"> 0.2987 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNext we'll decompose this matrix using a singular value decomposition (SVD), the mathematical procedure at the heart of PCA. A SVD will decompose (break apart) our original matrix (X) into 3 separate matrices (U, $\\Delta$, V). The original data matrix can be reconstructed via matrix multiplication/linear algebra of these 3 matrices:\n\n<font style=\"font-size: 14pt\">\n$$\nX = U \\Delta V^T\n$$\n</font>\n\nBriefly, U contains information about the rows (e.g., years), V contains information about the columns (e.g., measures), and $\\Delta$ is a diagonal matrix of \"weights\" called singular values that are the square root of the eigenvalues ($\\lambda$).\n\nComputing the SVD of our data matrix in R requires just one line of code:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nhawks_data_svd <- svd(hawks_data_mat) # singular value decomposition (SVD)\n```\n:::\n\n\n<br >\n\n## Eigen Values\n\nOur original data matrix was 11 rows (years) x 9 columns (measures); therefore, the SVD of that matrix will produce 9 singular values/components -- with the smaller side dictating the number of components produced.\n\nWhich components are important? Which ones explain the most variance? Are some of the components just noise?\n\nA good first pass at answering these questions is to examine the scree plot -- plotting the components as a function of variability explained.\n\nTo do this, let's first square the singular values ($\\Delta$) and sum them together. This is called __inertia__.\n\n<font style=\"font-size: 14pt\">\n$$\nI = \\Sigma\\lambda = \\Sigma\\Delta^2\n$$\n</font>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninertia <- sum(hawks_data_svd$d^2) # Calculates inertia\n```\n:::\n\n\nNext, we'll use the inertia to calculate the percentage of variability explained for each component and plot the scree:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Calculates values for the scree plot\nscree <- tibble(eigs = hawks_data_svd$d^2, \n                perc_explained = (eigs/inertia)*100,\n                comps = 1:length(eigs)\n                )\n\n# Scree plot\nggplot(scree, aes(factor(comps), eigs)) +\n  geom_point() +\n  geom_path(aes(group = 1)) +\n  scale_y_continuous(sec.axis = sec_axis(~./inertia * 100, \n                                         name = \"Explained Variance (%) \\n\"\n                                         )\n                     ) +\n  labs(x = \"\\n Components\", y = \"Eigenvalues \\n\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nAs we can see from the scree plot, the first 3 components comprise 91.75% of the total variance, suggesting that these first three components are important to understanding the structure of the data set. The remaining components explain only 8.25% of the variability and may perhaps be noise.\n\nIs there any way to statistically show that these components are important? One method is permutation testing. If you are unfamiliar with permutation testing, we recommend checking out our Shiny dashboard <a href=\"https://mattkmiecik.shinyapps.io/boot-perm-dash/\" target=\"_blank\">here</a>.\n\nBriefly, to perform permutation testing we will scramble the information down the columns, thus breaking the relationship between the years and their measures. Then, we will re-compute the SVD for the new scrambled data matrix. We will repeat these steps 2,000 times, forming a null distribution of eigenvalues from which to compare our originally observed eigenvalues.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nperm_iters <- 2000  # number of permutation iterations\nset.seed(2019)      # sets seed for reproducible results\n\n# Initializes matrix to hold permutation results\nperm_res <- matrix(data = 0, nrow = perm_iters, ncol = length(hawks_data_svd$d))\n\nfor(i in 1:perm_iters){\n  \n  this_matrix <- apply(hawks_data_mat, 2, sample) # scrambles down columns\n  perm_res[i,] <- svd(this_matrix)$d^2 # saves eigenvalues to perm_res\n  \n}\n```\n:::\n\n\nNow let's visualize these results against the observed values. We'll determine that a component is significant if its original observed eigenvalue is greater than 95% of the values derived from the null distribution (i.e., permutation testing).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Converts to long format for plotting\nperm_res_long <- as_tibble(perm_res) %>% \n  gather(comps, eigen) %>%\n  mutate(comps = as.numeric(gsub(\"V\", \"\", comps)))\n\n# Plots permutation results\nggplot(perm_res_long, aes(eigen)) +\n  geom_histogram(binwidth = 1) +\n  geom_vline(data = scree, \n             aes(xintercept = eigs), \n             color = rdgy[3], \n             linetype = 2\n             ) +\n  coord_cartesian(ylim = c(0, 800)) +\n  scale_y_continuous(minor_breaks = NULL) +\n  scale_x_continuous(minor_breaks = NULL) +\n  labs(x = \"\\n Eigenvalue\", \n       y = \"Frequency \\n\", \n       caption = \"\\n Note: Originally observed eigenvalues denoted by red dashed line.\"\n       ) +\n  facet_wrap(~comps) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nIt looks like the only components that have a shot at being greater than 95% of the null distribution are components 1 and 2. Let's see if this is the case:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nscree_sig <- perm_res_long %>% \n  group_by(comps) %>% \n  summarise(ul = quantile(eigen, .975)) %>% # computes upper limit of 95%\n  inner_join(., scree, by = \"comps\") %>%\n  mutate(sig = ifelse(eigs>ul, \"p < .05\", \"p > .05\"))\n\nggplot(scree_sig, aes(factor(comps), eigs)) +\n  geom_path(aes(group = 1), color = rdgy[8], linetype = 2) +\n  geom_point(aes(color = sig), size = 2) +\n  scale_y_continuous(sec.axis = sec_axis(~./inertia * 100, \n                                         name = \"Explained Variance (%) \\n\"\n                                         )\n                     ) +\n  scale_color_manual(values = c(rdgy[3], rdgy[9]), name = NULL) +\n  labs(x = \"\\n Components\", y = \"Eigenvalues \\n\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nWhat we suspected was correct: given a null distribution/hypothesis, only components 1 and 2 were greater than 95% permuted eigenvalues. In other words, there is less than a 5% chance that the pattern of the results seen on components 1 and 2 are this extreme given that the null hypothesis is true (i.e., no relationship). Therefore, we'll pay special attention to components 1 and 2.\n\nNow that we know what components may be more important than others, let's take a look at what we can learn from examining factor scores for the rows (years) and the columns (measures).\n\n<br >\n\n### Row-wise Factor Scores\n\nWe can explore how the years are seen through the components by first scaling (multiplying) the U matrix by the singular values. <font style=\"font-size: 14pt\"> $$F_{years} = U\\Delta$$ </font> The `%*%` operator performs matrix algebra:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nyears <- hawks_data_svd$u %*% diag(hawks_data_svd$d)  # scaling years data\nrownames(years) <- rownames(hawks_data_mat)           # adds rownames\n```\n:::\n\n\nNow let's visualize the factor scores for components 1 and 2:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Builds dataframe of row-wise factor scores with notable events\nyears_fs <- as_tibble(years) %>%\n  mutate(Season = hawks_data_wide$Season) %>%\n  left_join(., hawks_events, by = \"Season\") # imports notable events\n\n# Plots factor scores colored by Stanley Cup wins\n# tip: surrounding an action in R with () will automatically plot to screen\n(years_fs_scw <- ggplot(years_fs, aes(V1, V2, color = SCW)) +\n  geom_vline(xintercept = 0, alpha = 1/3) +\n  geom_hline(yintercept = 0, alpha = 1/3) +\n  geom_point() +\n  coord_cartesian(xlim = c(-7,7), ylim = c(-7,7)) +\n  scale_color_manual(values = c(rdgy[9], rdgy[2]), name = \"Stanley Cup Wins\") +\n  geom_text_repel(aes(label = Season), segment.alpha = 0, show.legend = FALSE) +\n  pca_furnish +\n  theme(legend.position = \"bottom\")\n)\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nThe above graph plots the years as they are seen through the first 2 dimensions of the PCA and colors the points based on Stanley Cup wins. The years cluster together into three distinct groups\n\n* The 2007-2008 and 2008-2009 seasons\n* The 2013 season\n* The 2010-2018 seasons\n\nwhile the 2010 season is near the origin -- meaning it doesn't contribute much to either group. Interestingly, there seems to be no clear pattern in regards to regular season play and Stanley Cup wins because these winning seasons are not clustered together.\n\nA pattern that does seem to emerge is the improvement of the team over time across principal component 1 (x-axis). Principal component 2 is dominated by the 2012-2013 season, probably due to the uniqueness of this season: shortened season due to lockout, Presidents' trophy winners, and Stanley Cup champions.\n\nLet's now color the points based on playoff performance:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plots factor scores colored by playoff performance\n# tip: surrounding an action in R with () will automatically plot to screen\n(years_fs_pf <- ggplot(years_fs, aes(V1, V2, color = PF)) +\n  geom_vline(xintercept = 0, alpha = 1/3) +\n  geom_hline(yintercept = 0, alpha = 1/3) +\n  geom_point() +\n  coord_cartesian(xlim = c(-7,7), ylim = c(-7,7)) +\n  scale_color_brewer(palette = \"Dark2\", direction = -1) +\n  geom_text_repel(aes(label = Season), segment.alpha = 0, show.legend = FALSE) +\n  pca_furnish +\n  theme(legend.position = \"bottom\")\n)\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nOne pattern of results that emerges, somewhat unexpectedly, is that the 2007-2008 and 2017-2018 seasons are contrasted on principal component 1 (x-axis). In both seasons, the Hawks missed the playoffs (did not qualify); however, the 2018 season is more similar to the seasons in which the Hawks made the playoffs. These results also highlight the 2015 Stanley Cup winning season, which is surrounded by seasons with early first round playoff exits. This may be indicative of an average regular season in 2015 (in respect to the Hawks), but an exceptional post season performance.\n\n<br >\n\n## Column-wise Factor Scores\n\nThrough the PCA, we are also able to examine the factor scores from the team metrics/stats (i.e., columns). Let's scale the V matrix by the singular values to obtain the factor scores. <font style=\"font-size: 14pt\">$$F_{metric} = V\\Delta$$</font> Again, the `%*%` operator performs matrix algebra:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmetric <- hawks_data_svd$v %*% diag(hawks_data_svd$d) # scaling years data\nrownames(metric) <- colnames(hawks_data_mat)          # adds rownames\n\n# Converts to long format for plotting\nmetric_fs <- as_tibble(metric) %>% mutate(Metric = colnames(hawks_data_mat))\n```\n:::\n\n\nNow let's visualize the factor scores for components 1 and 2:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Plots the column-wise factor scores\n(metric_plot <- ggplot(metric_fs, aes(V1, V2)) +\n  geom_vline(xintercept = 0, alpha = 1/3) +\n  geom_hline(yintercept = 0, alpha = 1/3) +\n  geom_point() +\n  coord_cartesian(xlim = c(-7,7), ylim = c(-7,7)) +\n  geom_text_repel(aes(label = Metric), segment.alpha = 0) +\n  pca_furnish\n)\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-18-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSimilar to the year-wise factor scores, we obtained 3 clusters of team-wise metrics across components 1 and 2. Component 1 contrasts penalty minutes (both drawn and taken) with Corsi (both For and Against), time on ice (TOI) and goals against (GA). \n\nThis contrast suggests a negative relationship with these metrics (e.g., as penalty minutes served increased, Corsi against decreased). This is sort of paradoxical, but it is similar to what we saw above with the correlation plot.\n\nAdditionally, the second component is dominated by Shooting Percentage, Save Percentage, and Goals For -- and contrasted by GA. It makes sense that increases in Shooting Percentage would be related to increases in Goals For, which would also be related to decreases in Goals Against.\n\n<br >\n\n## Factor Score Comparisons\n\nTo provide more context, let's compare the year-wise and metric-wise factor scores side-by-side:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngrid_furnish <- theme(legend.position = \"none\",\n                      axis.text = element_blank()\n                      )\n# Plots side-by-side\ngrid.arrange(years_fs_pf + grid_furnish, \n             metric_plot + grid_furnish, \n             nrow = 1\n             )\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-19-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nFrom here we gain a rich perspective of how each year-wise clustering is described through patterns in team stats:\n\n* Cluster 1: the 2007-2008 and 2008-2009 seasons are well described by elevated penalty minutes (both drawn and taken)\n* Cluster 2: the 2011-2018 seasons are well described by elevated Corsi (both For and Against), Goals Against (GA), and time on ice (TOI)\n* Cluster 3: the 2012-2013 season was characterized by a high powered offense (elevated Shooting % and Goals For) and excellent defense (high Save % and low Goals Against)\n\n<br >\n\n## Contributions\n\nWe can also take a look at how much each season (row) or metric (column) contributes to each component. To calculate the contribution of each component, we square each factor score and divide it by the sum of squared factor, which is also the eigenvalue.\n\n<font style=\"font-size: 14pt\">\n$$contribution = \\frac{f^2}{\\Sigma f^2} = \\frac{f^2}{\\lambda}$$\n</font>\n\nHere is a function that will compute the contributions:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Contribution calculator function ----\ncontribution <- function(vector, sign = TRUE) {\n  \n  vector_sq <- vector^2\n  vector_sq_sum <- sum(vector_sq)\n  \n  if (sign == TRUE) {\n    vector <- vector_sq/vector_sq_sum*sign(vector)\n  } else {\n    vector <- vector_sq/vector_sq_sum\n  }\n  \n}\n```\n:::\n\n\n## Row-wise Contributions\n\nNow let's apply the above function to calculate the contributions of the years (rows):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculates the contribution of each row (e.g., season) ----\ncontributions_years <- apply(years, 2, contribution)\n\n# add column names\ncolnames(contributions_years) <- paste0(\"Component_\",1:ncol(contributions_years))\n\n# converts contributions to long format ----\ncontributions_years_long <- contributions_years %>% \n  as_tibble() %>%                                   \n  mutate(Season = rownames(years)) %>%              # add Seasons \n  reshape2::melt(value.name = \"Contributions\") %>%  # ensure values are called contributions\n  group_by(variable) %>%\n  mutate(Contributes = ifelse(abs(Contributions) > abs(mean(Contributions)), \n                              \"Yes\", \n                              \"No\")\n         ) %>%\n  ungroup()\n```\n:::\n\n\nNow let's plot these contributions. Any years that have contributions greater than the mean are said to contribute to the variability on that component:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculate the mean of each component for graphing ----\ncontributions_years_means <- contributions_years_long %>%\n  group_by(variable) %>%\n  summarise(mean = mean(Contributions)) %>%\n  ungroup()\n\n# looking only at first two components ----\nyear_contrib <- contributions_years_long %>% \n  filter(variable %in% c(\"Component_1\", \"Component_2\"))\n  \nyear_contrib_means <- contributions_years_means %>%\n  filter(variable %in% c(\"Component_1\", \"Component_2\"))\n\n\n# plot the contribution bars with the +/- mean\n# filtering only the first two components \nggplot(year_contrib, aes(x = Season, y = Contributions, fill = Contributes)) +             \n  geom_bar(stat = \"identity\", color = \"black\") +\n  coord_flip(ylim = c(-.9, .9)) +\n  geom_hline(data = year_contrib_means, \n             aes(yintercept = mean), \n             linetype = \"dashed\", \n             alpha = 0.5\n             ) +  \n  geom_hline(data = year_contrib_means, \n             aes(yintercept = -mean), \n             linetype = \"dashed\", \n             alpha = 0.5\n             ) +\n  scale_fill_manual(values = c(rdgy[8], rdgy[3])) +\n  labs(x = \"Season \\n\",\n       y = \"\\n Contributions\",\n       caption = \"\\nNote: Dashed lines represent the mean contribution.\"\n       ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\"\n        ) +\n  facet_wrap(~variable, \n             labeller = as_labeller(c(`Component_1` = \"Component 1\\n\", \n                                      `Component_2` = \"Component 2\\n\"\n                                      )\n                                    )\n             )\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nSeason 2008 and 2009 contribute more than the mean season on the negative side of component 1, while seasons 2016 to 2018 contribute more than the mean season on the positive side of component 1. In other words, the 2008 and 2009 seasons are in stark contrast to the 2016-2018 seasons on component 1.\n\nFor component 2, only season 2013 contributes more than the mean season and on the negative side of component 2. Thus, component 2 likely reflects the 2013 season.\n\n## Column-wise Contributions\n\nNow let's repeat this procedure for the metrics (columns):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculates the contribution of each row (e.g., metric)\ncontributions_metric <- apply(metric, 2, contribution)\n\n# add column names\ncolnames(contributions_metric) <- paste0(\"Component_\",1:ncol(metric)) \n\n# converts contributions to long format\ncontributions_metric_long <- as_tibble(contributions_metric) %>%\n  mutate(Metric = rownames(contributions_metric)) %>%\n  reshape2::melt(value.name = \"Contributions\") %>%\n  group_by(variable) %>%\n  mutate(Contributes = ifelse(abs(Contributions) > abs(mean(Contributions)), \n                              \"Yes\", \n                              \"No\")\n         ) %>%\n  ungroup()\n```\n:::\n\n\nAnd here are the contribution plots for the metrics on components 1 and 2:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# calculate the mean of each component for graphing\ncontributions_metric_means <- contributions_metric_long %>%\n  group_by(variable) %>%\n  summarise(mean = mean(Contributions))\n\n# looking only at first two components ----\nmetric_contrib <- contributions_metric_long %>% \n  filter(variable %in% c(\"Component_1\", \"Component_2\"))\n  \nmetric_contrib_means <- contributions_metric_means %>%\n  filter(variable %in% c(\"Component_1\", \"Component_2\"))\n\n# plot the contributions bars with +/-mean\n# filtering only the first two components\nggplot(metric_contrib, aes(x = reorder(Metric, Contributions), y = Contributions, fill = Contributes)) +             \n  geom_bar(stat = \"identity\", color = \"black\") +\n  coord_flip(ylim = c(-.9, .9)) +\n  geom_hline(data = metric_contrib_means, \n             aes(yintercept = mean), \n             linetype = \"dashed\", \n             alpha = 0.5\n             ) +  \n  geom_hline(data = metric_contrib_means, \n             aes(yintercept = -mean), \n             linetype = \"dashed\", \n             alpha = 0.5\n             ) +\n  scale_fill_manual(values = c(rdgy[8], rdgy[3])) +\n  labs(x = \"Metric \\n\",\n       y = \"\\n Contributions\",\n       caption = \"\\nNote: Dashed lines represent the mean contribution.\"\n       ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\"\n        ) +\n  facet_wrap(~variable, \n             labeller = as_labeller(c(`Component_1` = \"Component 1\\n\", \n                                      `Component_2` = \"Component 2\\n\"\n                                      )\n                                    )\n             )\n```\n\n::: {.cell-output-display}\n![](post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files/figure-html/unnamed-chunk-24-1.png){fig-align='center' width=672}\n:::\n:::\n\n\nPenalty minutes drawn (PEND) and penalty minutes served (PENT) contribute more than the mean metric to the negative side of component 1; while Corsi Against (CA), Corsi For (CF), Goals Against (GA), and Time on Ice (TOI) contribute more than the mean metric to the positive side of component 1. \n\nGoals For (GF), Save Percentage (SavePerc), and Shooting Percentage (ShootPerc) contribute more than the mean metric to the negative side of component 2; while Goals Against (GA) contributes more than the mean metric to the positive side of component 2.\n\nGoals Against (GA) appears to contribute to both the positive side of component 1 and 2.\n\nTaking into both the row-wise and column-wise contributions confirm the factor score plots:\n\n**Component 1**\n\n* Season 2008 and 2009 are associated with penalty minutes drawn and served (PEND and PENT, respectively) and both contribute negatively to component 1. \n* On the other hand, seasons 2016 to 2018 are associated with Corsi For (CF), Corsi Against (CA), Goals Against (GA), and Time on Ice (TOI) and contribute to the positively to component 1. \n\n**Component 2** \n\n* Season 2013 is associated with Goals For (GF), Save Percentage (SavePerc), and Shooting Percentage (ShootPerc) and contribute negatively to component 2. \n* On the other hand, Goals Against (GA) contributes positively to component 2.  \n\n<br >\n\n# Summary\n\nIn this investigation we used z-scores, correlations, and Principal Components Analysis (PCA) to examine 11 years of data from the Chicago Blackhawks spanning from the 2007-2008 season to the 2017-2018 season. We determined that the first two components described these data well across time though various readily available and simple metrics, such as goals scored, penalty minutes served, shooting percentage, etc.\n\nThe main take away messages include:\n\n1. The 2007-2008 & 2008-2009 seasons are distinctly opposite when compared to the 2015-2018 seasons. They differ in this respect due to opposing patterns in penalty minutes (served and drawn) and Corsi (both For and Against).\n\n2. The Hawks had an incredible 2012-2013 season that resulted in the Presidents' trophy and a Stanley Cup win. This was reflected in the second principal component and was associated with both heightened offensive (e.g., Shooting Percentage, Goals For) and defensive (e.g., Save Percentage) statistics.\n\nDo these components suggest certain patterns of regular season statistics that predict Stanley Cup performance? No. There seems no distinct pattern that groups the Stanley Cup winning seasons on a separate component; however, the 2012-2013 season did emerge as a unique season in comparison to the other seasons.\n\nFuture directions include logistic regression approaches that utilize factor scores from this PCA to understand relationships between regular season stats and playoff performance.\n\n<br >\n\n# Exercise\n\nEven though component 3 is not significant according to the permutation testing, does it still tell us something meaningful? Try replicating these analyses above and let us know what you think!\n",
    "supporting": [
      "post-Exploring-11-Years-of-Chicago-Blackhawks-Data-using-Principal-Components-Analysis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}